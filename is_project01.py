# -*- coding: utf-8 -*-
"""IS_project01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/158ZULT1XVM_CRIJaBpuYcULZZ5W2r0EX

**Import Libraries**
"""

# Basic imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning imports
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# For saving model
import pickle

"""**Load the Dataset**"""
data = pd.read_csv(r"E:\Year 03\Sem 02\Notes\Intelligent Systems (IS)\new_repo01\data\boston_house_prices_dataset.csv")

# Show first 5 rows
data.head()

"""**Explore the Dataset**"""

# Shape of dataset
print("Shape:", data.shape)

# Check for null values
print("Null Values:\n", data.isnull().sum())

# Dataset summary
data.describe()

"""**Visualize the Data**"""

# Correlation heatmap
plt.figure(figsize=(10,8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

"""**Prepare Data for Model**"""

# Define features and target
X = data.drop('MEDV', axis=1)
y = data['MEDV']

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Train the Model**"""

# Train Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

"""**Evaluate the Model**"""

# Predict on test set
y_pred = model.predict(X_test)

# Evaluation metrics
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))

"""**Save the Trained Model**"""

# Save model to file
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

print("Model saved as model.pkl")

"""**Sample Prediction (Optional)**"""

# Predict using one test input
sample = X_test.iloc[0]
prediction = model.predict([sample])
print("Prediction for sample:", prediction)

# Import Libraries
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

# Load the model & Dataset
# Load trained model
with open("model.pkl", "rb") as file:
    model = pickle.load(file)

# Load dataset
data = pd.read_csv("data/boston_house_prices_dataset.csv")

# App Title and Description
st.set_page_config(page_title="Boston House Price Predictor", layout="wide")

st.title("üè† Boston Housing Price Prediction App")
st.markdown("""
This Streamlit web app allows you to explore the **Boston housing dataset**, visualize key features,  
and predict house prices using a trained machine learning model.
""")

# Sidebar Navigation
menu = st.sidebar.selectbox("Choose Section", ["Home", "Explore Data", "Visualizations", "Model Prediction", "Model Performance"])

# "Home" Section
if menu == "Home":
    st.subheader("üìä Dataset Overview")
    st.write("Shape of dataset:", data.shape)
    st.write(data.head())

# "Explore Data" Section
elif menu == "Explore Data":
    st.subheader("üîç Explore Dataset")

    if st.checkbox("Show all columns"):
        st.write(data.columns)

    if st.checkbox("Show data types"):
        st.write(data.dtypes)

    if st.checkbox("Show missing values"):
        st.write(data.isnull().sum())

    selected_cols = st.multiselect("Select columns to display", data.columns)
    if selected_cols:
        st.dataframe(data[selected_cols].head())

# "Visualizations" Section
elif menu == "Visualizations":
    st.subheader("üìà Visualizations")

    st.markdown("### Correlation Heatmap")
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(data.corr(), annot=True, cmap="coolwarm")
    st.pyplot(fig)

    st.markdown("### Distribution Plot")
    selected_col = st.selectbox("Choose a column to plot", data.columns)
    fig2, ax2 = plt.subplots()
    sns.histplot(data[selected_col], kde=True)
    st.pyplot(fig2)

# "Model Prediction" Section
elif menu == "Model Prediction":
    st.subheader("üè° Predict House Price")

    # Show only first 6 features for input (for simplicity)
    user_input = {}
    for col in data.columns[:-1][:6]:  # Show only first 6 for demo
        user_input[col] = st.number_input(f"Enter value for {col}", value=float(data[col].mean()))

    input_df = pd.DataFrame([user_input])

    if st.button("Predict Price"):
        prediction = model.predict(input_df)[0]
        st.success(f"Estimated Price: ${prediction * 1000:.2f}")

# "Model Performance" Section
elif menu == "Model Performance":
    st.subheader("üìä Model Evaluation Metrics")

    from sklearn.metrics import mean_squared_error, r2_score

    X = data.drop("MEDV", axis=1)
    y = data["MEDV"]
    y_pred = model.predict(X)

    mse = mean_squared_error(y, y_pred)
    r2 = r2_score(y, y_pred)

    st.write(f"**Mean Squared Error (MSE):** {mse:.2f}")
    st.write(f"**R¬≤ Score:** {r2:.2f}")

    st.markdown("### Actual vs Predicted")
    fig3, ax3 = plt.subplots()
    ax3.scatter(y, y_pred)
    ax3.set_xlabel("Actual")
    ax3.set_ylabel("Predicted")
    st.pyplot(fig3)

import os
import pandas as pd

csv_path = os.path.join(os.path.dirname(__file__), 'data', 'boston_house_prices_dataset.csv')
data = pd.read_csv(csv_path)

print(data.head()) 